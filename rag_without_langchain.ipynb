{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbed5996-1bf5-4eaf-8bfc-c9dec7773ebc",
   "metadata": {},
   "source": [
    "To set up a Retrieval-Augmented Generation (RAG) system using your Mac with the Ollama platform, weâ€™ll need to handle a few main components:\n",
    "\n",
    "1.\tLLM Model (using Ollama): Weâ€™ll call an open-source language model through Ollama for generation.\n",
    "2.\tData Storage and Retrieval: This component indexes and retrieves relevant documents in response to a query.\n",
    "3.\tApplication Logic: This ties together the retrieval and generation, handling inputs and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16158b4e-656e-4212-b3cb-4e7b4b29ade0",
   "metadata": {},
   "source": [
    "# 1. LLM Models (using Ollama)\n",
    "- Download and install ollama from ollama.com\n",
    "- Install some LLM models in your machine:\n",
    "  ```ollama install <model_name>```\n",
    "- List the existing models\n",
    "- Consider a Model with Retrieval-Augmented Fine-Tuning (like LlamaIndex, GPT-Neo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8092257a-d867-44f3-8a1a-ac3f5e61bd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                               ID              SIZE      MODIFIED     \n",
      "wizardlm-uncensored:latest         886a369d74fc    7.4 GB    2 months ago    \n",
      "wizard-vicuna-uncensored:latest    72fc3c2b99dc    3.8 GB    2 months ago    \n",
      "llava:latest                       8dd30f6b0cb1    4.7 GB    4 months ago    \n",
      "llama2-uncensored:latest           44040b922233    3.8 GB    4 months ago    \n",
      "phi3:medium                        1e67dff39209    7.9 GB    4 months ago    \n",
      "llama3:latest                      a6990ed6be41    4.7 GB    6 months ago    \n",
      "llama2:latest                      78e26419b446    3.8 GB    6 months ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c75b323-9883-45ec-a52c-884ef4c103fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ca08678-cfc6-4907-be08-8553e5b09a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "208597e3-a072-4702-97de-0d0a03c70956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama(prompt, model_name=\"llama2\"):\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/v1/completions\",\n",
    "        json={\"model\": model_name, \"prompt\": prompt},\n",
    "    )\n",
    "    return response.json()['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3435d6f-2ad4-4a95-a68a-c182afa56fde",
   "metadata": {},
   "source": [
    "Testing call_ollama() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95e7ade2-7ec6-441c-9c4e-f290478ac613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ðŸ‘‹'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"say hello world as an emoji!\"\n",
    "call_ollama(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed109f53-7268-40a0-947b-2c5ed595c4a9",
   "metadata": {},
   "source": [
    "# 2. Loading .pdf and .docx to a Data Storage (using FAISS IndexFlatL2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec57e78c-63cb-4b6c-bec5-be38ed6427b2",
   "metadata": {},
   "source": [
    "### Converting from .pdf to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34332506-79e4-4929-907e-ca03958b8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78324aee-6e6b-4afe-8560-050fb593c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF for PDFs\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(file_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text(\"text\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f906327-c966-44a1-af14-a759efcf54a6",
   "metadata": {},
   "source": [
    "### Converting from .docx to text (using python-docx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e059972-e18e-4ddd-8aaf-6482e3846c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cebd064-bab6-4160-bbe5-8f95f735dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "\n",
    "def load_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    text = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb12e2-9fd8-4ef3-a4b0-7b11568fd93d",
   "metadata": {},
   "source": [
    "### Converting text to embedding (using transformer from HuggingFace 'all-MiniLM-L6-v2' model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7985e9ab-37d0-4a17-ab32-899c88d068d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers torch ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85823ba9-ea03-453b-8aeb-3d01fbc33464",
   "metadata": {},
   "source": [
    "- sentence-transformers/all-MiniLM-L6-v2\n",
    "- distilbert-base-uncased\n",
    "- all-mpnet-base-v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9c37ae1-064e-47d8-b335-3e360e36aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def embed_text(text):\n",
    "    # Tokenize input text and convert to tensor\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512) #returns PyTorch tensors\n",
    "    \n",
    "    # Forward pass through the model to get hidden states\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get the embeddings from the last hidden layer\n",
    "    hidden_states = outputs.last_hidden_state  # Shape: (1, seq_len, hidden_dim)\n",
    "    \n",
    "    # Average pool over the token embeddings to get a single vector\n",
    "    embedding = hidden_states.mean(dim=1).squeeze().numpy()  # Shape: (hidden_dim,)\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5add5f-ef18-45b6-89e7-e646d8268862",
   "metadata": {},
   "source": [
    "## Initialize the database (FAISS index for 768-dim embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9284750-d303-4d39-a8ab-66dd0a161153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad7c88-4aaa-40bb-9ebb-95981a94fba8",
   "metadata": {},
   "source": [
    "- IndexFlatL2\n",
    "- IndexIVFFlat\n",
    "- IndexHNSWFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1acda0c2-dc7e-4916-ae55-2aa0e8305841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "dimension = 384 #good for distilbert-base-uncased or sentence-transformers/all-MiniLM-L6-v2\n",
    "index = faiss.IndexFlatL2(dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ce9681-06ec-494c-bce6-f4061eba74ff",
   "metadata": {},
   "source": [
    "### Loading files from a folder into the database (FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7860c32d-72bc-4092-97f6-5fdef12f3495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_and_index_files(folder_path, index):\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Check file extension and load text\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            text = load_pdf(file_path)\n",
    "        elif filename.endswith(\".docx\"):\n",
    "            text = load_docx(file_path)\n",
    "        else:\n",
    "            continue  # Skip non-supported files\n",
    "        \n",
    "        # Embed and add to index\n",
    "        embedding = embed_text(text)\n",
    "        index.add(np.array([embedding]))\n",
    "        \n",
    "        # Track document content and metadata (optional)\n",
    "        documents.append({\"filename\": filename, \"content\": text, \"embedding\": embedding})\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ccafa14b-5a49-437b-8723-1ce4ec541347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents indexed: 1\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'folder_example/'\n",
    "documents = load_and_index_files(folder_path, index)\n",
    "print(f\"Total documents indexed: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c6e1a-5fb5-48ef-aef2-fbe5db18dbd3",
   "metadata": {},
   "source": [
    "### Retrieve documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce17eb80-065b-47c2-bf98-836997db7191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query_embedding, index, documents, top_k=3):\n",
    "    # Search for the nearest neighbors\n",
    "    distances, indices = index.search(np.array([query_embedding], dtype='float32'), top_k)\n",
    "    \n",
    "    # Print indices for debugging\n",
    "    print(f\"indices: {indices}, distances: {distances}\")\n",
    "    \n",
    "    # Ensure indices is structured correctly and has expected dimensions\n",
    "    if indices.size == 0 or indices[0][0] == -1:\n",
    "        print(\"No matching documents found.\")\n",
    "        return []  # Return empty list if no results are found\n",
    "\n",
    "    # Fetch top_k documents using indices\n",
    "    return [documents[i] for i in indices[0] if i < len(documents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6cd3c8-3f0c-4497-b80c-928fdd27126e",
   "metadata": {},
   "source": [
    "# Create the RAG Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0559ffa5-d2a8-4628-82a6-a30ceb3e8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(query, model_name=\"llama2\", top_k=3):\n",
    "    query_embedding = embed_text(query) \n",
    "\n",
    "    # 2. Retrieve relevant documents\n",
    "    relevant_docs = retrieve_documents(query_embedding, index, documents, top_k)\n",
    "    \n",
    "    # 3. Construct the prompt with file information\n",
    "    context = \"\\n\".join([f\"File: {doc['filename']}\\nContent:\\n{doc['content']}\" for doc in relevant_docs])\n",
    "    prompt = f\"\"\"\n",
    "    Context (from relevant documents):\n",
    "    {context}\n",
    "    \n",
    "    Question: {query}\n",
    "    \n",
    "    Answer strictly based on the provided context. If the context does not include any information relevant to the question, respond exactly with \"The context does not provide information on this topic.\"\n",
    "    \"\"\"\n",
    "\n",
    "    # 4. Call the language model\n",
    "    response = call_ollama(prompt, model_name)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870a99a9-4026-4c98-9ec9-54278cc4eb6c",
   "metadata": {},
   "source": [
    "# Testing everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "14eca494-ddcc-4fb7-b1fa-f6fe2ca6becb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices: [[0 1 2]], distances: [[33.14148 33.14148 33.14148]]\n",
      "Northwave cybersecurity refers to a company or organization that specializes in providing cybersecurity services and products. The name \"Northwave\" suggests that the company is focused on providing cutting-edge security solutions for businesses and organizations. From the context provided, it appears that Northwave may be involved in developing and implementing artificial intelligence (AI) models for cybersecurity purposes. However, without further information, it is impossible to determine the specific nature of Northwave's services or products.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Northwave cybersecurity\"\n",
    "response = rag_pipeline(query)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
